---
title: "Modelling"
author: "Gauthami"
date: "5/1/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(ggplot2)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
library(e1071)
library(xgboost)
library(stringr)
library(lubridate)
library(tm)
library(rms)
library(glmnet)
library(pROC)
library(kernlab)
```


```{r}
test =read.csv("~/Desktop/Assignement/LoansTest_1.csv",stringsAsFactors=FALSE)
train_down = read.csv("~/Desktop/Assignement/LoansTrain_1.csv",stringsAsFactors=FALSE)

```

```{r}
test$percent_bc_gt_75
```


```{r}
colnames(test)
```


```{r}
train_down <- 
  caret::downSample(x = train[, !(names(train) %in% c("loan_status"))], 
                    y = as.factor(train$loan_status), yname = "loan_status")

base::prop.table(table(train_down$loan_status))
```

```{r}
dim(train_down)
```


```{r}

train_down$loan_status = ifelse(train_down$loan_status == "FALSE","Current","Default")
train_down$loan_status = factor(train_down$loan_status,levels = c("Default","Current"))
levels(train_down$loan_status)
```

```{r}
100*nrow(train_down %>% filter(loan_status =="Default"))/nrow(train_down)
```


```{r}
loan_status = train_down$loan_status
dummy_model = dummyVars(loan_status ~ .,train_down,fullRank = TRUE)
train_down = as.data.frame(predict(dummy_model,train_down))
train_down$loan_status = loan_status
rm(loan_status)
```




```{r}
loan_status = test$loan_status
dummy_model1 = dummyVars(loan_status ~ .,test,fullRank = TRUE)
test = as.data.frame(predict(dummy_model1,test))
test$loan_status = loan_status
rm(loan_status)
```

```{r}

is.factor(test$loan_status)
```

```{r}
dim(test)
```


```{r}
100*nrow(test %>% filter(loan_status =="Default"))/nrow(test)
```




```{r}
getIndexsOfColumns <- function(t,column_names){
    return(match(column_names,colnames(t)))
}
```


```{r}
set.seed(200)
#down sampling again so than we get more info when stacking
samp = downSample(train_down[-getIndexsOfColumns(train_down, c( "loan_status") )],as.factor(train_down$loan_status),yname="loan_status")
#choose small data for tuning 
train_index_tuning = createDataPartition(as.factor(samp$loan_status),p = 0.05,list=FALSE,times=1)
#choose small data for re-train
train_index_training = createDataPartition(as.factor(samp$loan_status),p = 0.1,list=FALSE,times=1)
```


```{r}
svmGrid = expand.grid(
                .sigma = as.numeric(sigest(loan_status ~.,data = samp[train_index_tuning,],scaled=TRUE)),
                .C = c(0.1,1,10)
                )

```

```{r}
getIndexsOfColumns <- function(t,column_names){
    return(match(column_names,colnames(t)))
}
ctrl <- trainControl(method = "cv",
    summaryFunction = twoClassSummary,
    classProbs = TRUE,
    number = 3
    )
```


```{r}
levels(samp$loan_status)
```

```{r}
svmTuned = train(
    samp[train_index_tuning,-getIndexsOfColumns(samp,"loan_status")],
    y =as.factor( samp[train_index_tuning,"loan_status"]),
    method = "svmRadial",
    tuneGrid = svmGrid,
    metric = "ROC",
    trControl = ctrl,
    preProcess = NULL,
    scaled = FALSE,
    fit = FALSE)

plot(svmTuned)

svmTuned
```

```{r}
svmTuned$results$sigma
```

```{r}
svm_model = ksvm(loan_status ~ .,
                 data = samp[train_index_training,],
                 kernel = "rbfdot",
                 kpar = list(sigma=0.03518655),
                 C = 0.1,
                 prob.model = TRUE,
                 scaled = FALSE)


```



```{r}
predict_loan_status_svm = predict(svm_model,test)

```



```{r}
predict_loan_status_svm  = as.data.frame(predict_loan_status_svm)
```


```{r}
predict_loan_status_svm

```



```{r}
predict_loan_status_svm <-as.factor(predict_loan_status_svm )
predict_loan_status <- as.factor(predict_loan_status)
rocCurve_svm = roc(response = test$loan_status,
               predictor = predict_loan_status_svm)

auc_curve = auc(rocCurve_svm)
```



```{r}
NROW(test$loan_status)
```

```{r}
c = confusionMatrix(predict_loan_status,test$loan_status,positive="Currrent")
```

```{r}
nrow(predict_loan_status_svm )
```

```{r}
CF_Matrix1<-table(test$loan_status, predict_loan_status > 0.5)
```


```{r}
table_perf = data.frame(model=character(0),
                        auc=numeric(0),
                        accuracy=numeric(0),
                        sensitivity=numeric(0),
                        specificity=numeric(0),
                        kappa=numeric(0),
                        stringsAsFactors = FALSE
                        )

table_perf[2,] = c("SVM",
  round(auc_curve,3),
  as.numeric(round(c$overall["Accuracy"],3)),
  as.numeric(round(c$byClass["Sensitivity"],3)),
  as.numeric(round(c$byClass["Specificity"],3)),
  as.numeric(round(c$overall["Kappa"],3))
  )

tail(table_perf,1)

```



```{r}



```

```{r}
rocCurve_svm = roc(response = test$loan_status,
               predictor = predict_loan_status_svm)

```


```{r}
auc_curve = auc(rocCurve_svm)
auc_curve 


```


```{r}


plot(rocCurve_svm,legacy.axes = TRUE,print.auc = TRUE,col="red",main="ROC(SVM)")
```





```{r}
set.seed(200)
#down sampling again so than we get more info when stacking
samp = downSample(train_down[-getIndexsOfColumns(train_down, c( "loan_status") )],as.factor(train_down$loan_status),yname="loan_status")

train_index_tuning = createDataPartition(as.factor(samp$loan_status),p = 0.1,list=FALSE,times=1)
```


```{r}
getNumericColumns<-function(t){
    tn = sapply(t,function(x){is.numeric(x)})
    return(names(tn)[which(tn)])
}

getCharColumns<-function(t){
    tn = sapply(t,function(x){is.character(x)})
    return(names(tn)[which(tn)])
}

getFactorColumns<-function(t){
    tn = sapply(t,function(x){is.factor(x)})
    return(names(tn)[which(tn)])
}
```


```{r}
library("xgboost")
etas = c(0.1,0.3)
alphas = c(0,0.5,1)
lambdas = c(0,0.5,1)

test_watchlist = list(
    test = xgb.DMatrix(
        data = as.matrix(samp[train_index_tuning,][getNumericColumns(samp)]),
        label = as.numeric(samp[train_index_tuning,"loan_status"])-1
    )
)
for(eta in etas){
    for(alpha in alphas){
        for(lambda in lambdas){
            model = xgb.train(
                data= xgb.DMatrix(
                    data = as.matrix(samp[-train_index_tuning,][getNumericColumns(samp)]),
                    label = as.numeric(samp[-train_index_tuning,"loan_status"])-1
                ),
                objective = "binary:logistic",
                nrounds = 350,
                watchlist = test_watchlist,
                eval_metric = "auc",
                early.stop.round = 10,
                alpha = alpha,
                lambda = lambda,
                eta = eta)
            gbm_perf[nrow(gbm_perf)+1,] = c(eta,alpha,lambda,model$bestScore)
        }
    }
}


```






```{r}
set.seed(400)
test_watchlist = list(
    test = xgb.DMatrix(
        data = as.matrix(samp[train_index_tuning,][getNumericColumns(samp)]),
        label = as.numeric(samp[train_index_tuning,"loan_status"])-1
    )
)

xgb_model = xgb.train(
                data= xgb.DMatrix(
                    data = as.matrix(samp[-train_index_tuning,][getNumericColumns(samp)]),
                    label = as.numeric(samp[-train_index_tuning,"loan_status"])-1
                ),
                objective = "binary:logistic",
                nrounds = 350,
                watchlist = test_watchlist,
                eval_metric = "auc",
                early.stop.round = 10,
                alpha = 0.5,
                lambda = 1.0,
                eta = 0.1)
```

```{r}
predict_loan_status_xgb = predict(xgb_model,as.matrix(test[getNumericColumns(test)]))

rocCurve_xgb = roc(response = test$loan_status,
               predictor = predict_loan_status_xgb)

auc_curve = auc(rocCurve_xgb)

plot(rocCurve_xgb,legacy.axes = TRUE,print.auc = TRUE,col="red",main="ROC(XGB)")
```


```{r}
predict_loan_status_label = ifelse(predict_loan_status_xgb>0.5,"Default","Current")
#NROW(predict_loan_status_label)
predict_loan_status_label <- as.factor(predict_loan_status_label)
test$loan_status <- as.factor(test$loan_status)
```


```{r}
#predict_loan_status_label <- as.factor(predict_loan_status_label)
c = confusionMatrix(predict_loan_status_label,test$loan_status,positive="Default")
```

```{r}
table_perf = data.frame(model=character(0),
                        auc=numeric(0),
                        accuracy=numeric(0),
                        sensitivity=numeric(0),
                        specificity=numeric(0),
                        kappa=numeric(0),
                        stringsAsFactors = FALSE
                        )

table_perf[4,] = c("XGB",
  round(auc_curve,3),
  as.numeric(round(c$overall["Accuracy"],3)),
  as.numeric(round(c$byClass["Sensitivity"],3)),
  as.numeric(round(c$byClass["Specificity"],3)),
  as.numeric(round(c$overall["Kappa"],3))
  )
table_perf[4,]
```


```{r}
c
```


```{r}
xgb.importance(model = xgb_model)
```

